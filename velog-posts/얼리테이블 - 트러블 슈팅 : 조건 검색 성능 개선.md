<h1 id="조건-검색-성능-개선">조건 검색 성능 개선</h1>
<h2 id="1-배경">1. 배경</h2>
<p>데이터 수가 증가함에 따라 현재 <code>Store</code> 엔티티와 연관된 검색 기능에서 성능 문제가 발생하고 있습니다.</p>
<h2 id="2-문제">2. 문제</h2>
<p><code>searchStoreQuery</code> 메서드에서 다수의 조인과 조건 필터링이 이루어지며 응답 속도가 저하됩니다. 이로 인해 사용자가 검색 결과를 확인하는 데 시간이 오래 걸리고, 서버의 리소스 사용량이 증가하는 문제가 발생합니다.</p>
<h3 id="21-원인">2.1 원인</h3>
<ul>
<li><strong>조건 검색의 비효율성</strong>: <code>BooleanExpression</code>을 이용한 필터링에서 인덱스 활용 부족</li>
<li><strong>반복적인 DB 접근</strong>: Redis 캐싱 미적용으로 인해 동일한 검색이 반복적으로 DB에 접근</li>
<li><strong>Lazy Loading으로 인한 N+1 문제 가능성</strong></li>
<li><strong>복잡한 검색 필터링 로직</strong>: 최적화가 필요</li>
</ul>
<hr />
<h2 id="3-성능-개선-방법">3. 성능 개선 방법</h2>
<h3 id="30-데이터-준비">3.0 데이터 준비</h3>
<ul>
<li>store 더미 데이터 50만 개 생성<ul>
<li><code>net.datafaker.Faker</code>를 사용하여 랜덤 데이터를 생성하고, 이를 DB에 저장합니다.</li>
</ul>
</li>
</ul>
<pre><code class="language-java">package com.gotcha.earlytable.domain.store;

import com.gotcha.earlytable.domain.file.FileService;
import com.gotcha.earlytable.domain.store.entity.Store;
import com.gotcha.earlytable.domain.store.enums.StoreCategory;
import com.gotcha.earlytable.domain.store.enums.StoreStatus;
import com.gotcha.earlytable.domain.user.UserRepository;
import com.gotcha.earlytable.domain.user.entity.User;
import com.gotcha.earlytable.global.enums.RegionBottom;
import com.gotcha.earlytable.global.enums.RegionTop;
import jakarta.annotation.PostConstruct;
import lombok.RequiredArgsConstructor;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;
import net.datafaker.Faker;

import java.util.ArrayList;
import java.util.List;
import java.util.Locale;
import java.util.Random;

@Component
@RequiredArgsConstructor
public class StoreDummyDataInitializer {

    private final StoreRepository storeRepository;
    private final UserRepository userRepository;
    private final FileService fileService;

    private final Random random = new Random();
    private final Faker faker = new Faker(Locale.KOREAN);

    private static final int STORE_COUNT = 500_000;

    @PostConstruct
    @Transactional
    public void init() {
        List&lt;User&gt; users = userRepository.findAll();

        if (users.isEmpty()) {
            throw new IllegalStateException(&quot;User가 존재하지 않습니다.&quot;);
        }

        List&lt;Store&gt; stores = new ArrayList&lt;&gt;();

        for (int i = 0; i &lt; STORE_COUNT; i++) {
            stores.add(createRandomStore(users));

            if (i % 10_000 == 0) { // 10,000개씩 배치 저장
                storeRepository.saveAll(stores);
                stores.clear();
                System.out.println(i + &quot; 개의 데이터를 저장 완료...&quot;);
            }
        }

        if (!stores.isEmpty()) {
            storeRepository.saveAll(stores);
        }

        System.out.println(&quot;총 &quot; + STORE_COUNT + &quot; 개의 더미 데이터 저장 완료!&quot;);
    }

    private Store createRandomStore(List&lt;User&gt; users) {
        return new Store(
                faker.company().name(), // 랜덤 상점명
                faker.phoneNumber().phoneNumber(), // 랜덤 전화번호
                faker.lorem().sentence(), // 랜덤 설명
                faker.address().fullAddress(), // 랜덤 주소
                randomEnum(StoreStatus.class), // 랜덤 StoreStatus
                randomEnum(StoreCategory.class), // 랜덤 StoreCategory
                randomEnum(RegionTop.class), // 랜덤 RegionTop
                randomEnum(RegionBottom.class), // 랜덤 RegionBottom
                getRandomElement(users), // 랜덤 User
                fileService.createFile() // New File
        );
    }

    private &lt;T extends Enum&lt;?&gt;&gt; T randomEnum(Class&lt;T&gt; enumClass) {
        T[] enumConstants = enumClass.getEnumConstants();
        return enumConstants[random.nextInt(enumConstants.length)];
    }

    private &lt;T&gt; T getRandomElement(List&lt;T&gt; list) {
        return list.get(random.nextInt(list.size()));
    }
}</code></pre>
<ul>
<li>build.gradle에 의존성 추가</li>
</ul>
<pre><code class="language-java">implementation 'net.datafaker:datafaker:2.0.2'</code></pre>
<ul>
<li>더미 데이터 예시</li>
</ul>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/8dac0c49-7111-400d-bcfd-a07bad819f35/image.png" /></p>
<h3 id="31-인덱스-최적화">3.1 인덱스 최적화</h3>
<p>현재 <code>storeName</code>, <code>regionTop</code>, <code>regionBottom</code>, <code>storeCategory</code> 등에 대해 적절한 인덱스가 없어 DB에서 검색하는 데 시간이 오래 걸립니다.</p>
<h3 id="해결-방법">해결 방법</h3>
<p>아래와 같이 인덱스를 추가하여 검색 성능을 개선할 수 있습니다</p>
<pre><code class="language-java">@Entity
@Table(name = &quot;store&quot;, indexes = {
@Index(name = &quot;idx_store_name&quot;, columnList = &quot;storeName&quot;),
@Index(name = &quot;idx_region_top&quot;, columnList = &quot;regionTop&quot;),
@Index(name = &quot;idx_region_bottom&quot;, columnList = &quot;regionBottom&quot;),
@Index(name = &quot;idx_store_category&quot;, columnList = &quot;storeCategory&quot;)
})
public class Store extends BaseEntity {

    // ...이하 생략

}
</code></pre>
<ul>
<li><p>기본 키와 외래 키는 이미 데이터베이스에서 자동으로 인덱스를 생성함</p>
<ul>
<li>JPA에서는 @Id(storeId) 와 @manyToOne(UserId), @OneToOne(fileId) 관계의 필드를 인덱스로 자동 생성</li>
</ul>
</li>
</ul>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/cc10fa6b-e0c0-4c34-8a45-9eac2ae248d6/image.png" /></p>
<ul>
<li>조건 중 검색어는 가게 이름과 대표 메뉴 이름을 LIKE 조건으로 검색하기 때문에 “%검색어” 나 “%검색어%” 처럼 정렬이 무의미한 경우는 인덱스가 의미가 없음 → 실제로 시간이 더 오래 걸림(인덱스 수정)</li>
<li>조건 중 가격은 자주 변경될 가능성이 높고, BETWEEN 조건이라 성능 개선이 크게 이루어지지 않을 가능성이 높음</li>
</ul>
<h3 id="적용-전후-성능-비교">적용 전/후 성능 비교</h3>
<ul>
<li><p>인덱스 적용 전</p>
<p>  <img alt="" src="https://velog.velcdn.com/images/take_the_king/post/7735e57b-2177-4b99-bf94-3a786d4c89d0/image.png" /></p>
</li>
</ul>
<ul>
<li><p>인덱스 적용 후</p>
<p>  <img alt="" src="https://velog.velcdn.com/images/take_the_king/post/e1300f3f-41b5-4745-a7a4-ed714dfd7771/image.png" /></p>
</li>
</ul>
<h3 id="결과">결과</h3>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/a351803f-aae8-43cc-84db-4503f536194b/image.png" /></p>
<p>전체적으로 성능이 개선되긴 했지만 큰 지역(31,813개)과 카테고리(85,001개)처럼 많은 양의 데이터를 가져오는 상황에서는 크게 유의미한 결과를 보여주진 못하고, <strong>작은 지역과 작은 지역(2,259개) + 카테고리(5,303개) 10% 이하의 데이터를 가져올 때는 큰 성능 향상이 있었습니다.</strong></p>
<h3 id="32-redis-캐싱-적용">3.2 Redis 캐싱 적용</h3>
<p>동일한 검색이 반복적으로 발생할 경우, 캐싱이 없으면 매번 DB에서 조회해야하는 문제가 있습니다.</p>
<h3 id="해결-방법-1">해결 방법</h3>
<p>동일한 검색이 반복적으로 발생할 경우, DB에서 매번 조회하는 대신 Redis를 이용해 캐싱함으로써 성능을 개선할 수 있습니다.</p>
<pre><code class="language-java">/**
     * 가게 조건 검색 메서드
     *
     * @param requestDto
     * @return
     */
    public List&lt;StoreSearchResponseDto&gt; searchStore(StoreSearchRequestDto requestDto) {
        String cacheKey = &quot;store_search:&quot; + getCacheKey(requestDto);

        // RBucket을 JsonJacksonCodec과 함께 사용
        RBucket&lt;String&gt; cachedResult = redissonClient.getBucket(cacheKey, JsonJacksonCodec.INSTANCE);

        Instant start = Instant.now(); // 시작 시간 기록

        // 캐시된 결과가 있으면 반환
        String resultJson = cachedResult.get();
        List&lt;StoreSearchResponseDto&gt; result = null;
        if (resultJson != null &amp;&amp; !resultJson.isEmpty()) {
            try {
                result = objectMapper.readValue(resultJson, objectMapper.getTypeFactory().constructCollectionType(List.class, StoreSearchResponseDto.class));
            } catch (Exception e) {
                log.error(&quot;Error deserializing cached result&quot;, e);
            }
        }

        if (result == null || result.isEmpty()) {
            // 캐시된 결과가 없으면 DB에서 조회 후 캐시에 저장
            result = storeRepository.searchStoreQuery(requestDto);

            try {
                String resultJsonToCache = objectMapper.writeValueAsString(result); // List to JSON
                cachedResult.set(resultJsonToCache, 10, TimeUnit.MINUTES); // 캐시 만료 시간은 10분으로 설정
            } catch (Exception e) {
                log.error(&quot;Error serializing result to cache&quot;, e);
            }
        }

        Instant end = Instant.now(); // 종료 시간 기록
        long elapsedTime = Duration.between(start, end).toMillis(); // 실행 시간(ms)

        log.info(&quot;searchStoreQuery 실행 시간: {} ms, 결과 개수: {}&quot;, elapsedTime, result.size());

        return result;
    }

    // 캐시 키를 위한 핵심 파라미터들만 조합하는 메소드
    private String getCacheKey(StoreSearchRequestDto requestDto) {
        return requestDto.getSearchWord() + &quot;:&quot; +
                requestDto.getRegionTop() + &quot;:&quot; +
                requestDto.getRegionBottom() + &quot;:&quot; +
                requestDto.getStoreCategory();
    }</code></pre>
<ul>
<li><p>적용 전</p>
<ul>
<li><p>테스트 1</p>
<p>  <img alt="" src="https://velog.velcdn.com/images/take_the_king/post/48f12384-b65b-4b86-8ab3-ddc3d96933ec/image.png" /></p>
</li>
</ul>
</li>
</ul>
<pre><code>    ![](https://velog.velcdn.com/images/take_the_king/post/6a23e3c5-d1ed-4845-93fb-21cccb90359a/image.png)


- 테스트 2

    ![](https://velog.velcdn.com/images/take_the_king/post/6c7da1b5-56d0-4dee-9092-5c60c405f43b/image.png)


    ![](https://velog.velcdn.com/images/take_the_king/post/d6b82e5e-d348-4819-8449-7910a38a4287/image.png)</code></pre><ul>
<li><p>적용 후</p>
<ul>
<li><p>테스트 1 - 캐싱 후</p>
<p>  <img alt="" src="https://velog.velcdn.com/images/take_the_king/post/769e0bea-f50b-457e-9888-a40133d36e7c/image.png" /></p>
</li>
</ul>
</li>
</ul>
<pre><code>- 테스트 2 - 캐싱 후

    ![](https://velog.velcdn.com/images/take_the_king/post/ecf41371-32f8-4272-8509-229b4252cfc7/image.png)</code></pre><h3 id="결과-1">결과</h3>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/961be8ac-e58e-47b6-958a-1993cfee910f/image.png" /></p>
<p><strong>데이터를 캐싱한 결과 평균 95% 이상의 성능 개선이 이루어졌습니다.</strong> 자주 조회되는 조건들에 경우에는 아주 효과적인 개선 방법이 될 수 있습니다. 하지만 캐시 적중률이 높지 않다면 결국에는 DB 조회가 일어날 것입니다.</p>
<p>또한, 모든 조회들을 캐싱에 담아두고 긴 시간동안 보관하면 메모리 부하가 발생할 것입니다. 그렇기 때문에 적절한 만료시간과 자주 조회되는 컬럼을 적용시키면 아주 효과적인 성능 개선이 이루어질 것입니다.</p>
<h3 id="주의사항"><strong>주의사항</strong></h3>
<ul>
<li><strong>변경 빈도 고려</strong>: 만약 가게 데이터가 자주 변경된다면, 캐시에 저장된 데이터와 DB의 데이터 간에 불일치(데이터 정합성 문제)가 발생할 수 있습니다. 이런 경우 캐시를 자주 무효화하거나 업데이트해야 하므로, 캐시 업데이트 작업이 빈번해져 오히려 Redis에 부하를 줄 수 있습니다.</li>
<li><strong>캐시 적중률 고려</strong>: 캐시 적중률이 높다면 대부분의 요청이 Redis에서 처리되어 DB 부하가 줄어들지만, 캐시 적중률이 낮으면 DB 조회가 빈번하게 발생합니다. 특히 캐시 미스가 잦은 경우, Redis와 DB 간의 네트워크 트래픽이 증가할 수 있습니다.</li>
</ul>
<h3 id="33-n--1-문제-해결">3.3 N + 1 문제 해결</h3>
<p><code>@OneToMany(fetch = FetchType.LAZY)</code> 관계에서 N+1 문제가 발생할 가능성이 있습니다.</p>
<h3 id="해결-방법-1hibernate-batch-size-조정">해결 방법 1(Hibernate Batch Size 조정)</h3>
<p><code>@BatchSize(size = 100)</code>를 사용하여 성능을 개선할 수 있습니다.</p>
<ul>
<li>store 엔티티</li>
</ul>
<pre><code class="language-java">@Entity
@Table(name = &quot;store&quot;, indexes = {
@Index(name = &quot;idx_store_name&quot;, columnList = &quot;storeName&quot;),
@Index(name = &quot;idx_region_top&quot;, columnList = &quot;regionTop&quot;),
@Index(name = &quot;idx_region_bottom&quot;, columnList = &quot;regionBottom&quot;),
@Index(name = &quot;idx_store_category&quot;, columnList = &quot;storeCategory&quot;)
})
public class Store extends BaseEntity {

    // ...

    @OneToOne(fetch = FetchType.LAZY)
  @JoinColumn(name = &quot;file_id&quot;, nullable = false)
  private File file;

    @BatchSize(size = 100)
  @OneToMany(mappedBy = &quot;store&quot;, cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY)
  private final List&lt;Menu&gt; menuList = new ArrayList&lt;&gt;();

    @BatchSize(size = 100)
  @OneToMany(mappedBy = &quot;store&quot;, cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY)
  private final List&lt;Review&gt; reviewList = new ArrayList&lt;&gt;();
}
</code></pre>
<ul>
<li>file 엔티티</li>
</ul>
<pre><code class="language-java">@Getter
@Entity
@Table(name = &quot;file&quot;)
@BatchSize(size = 100)
public class File extends BaseEntity {

    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long fileId;

    @BatchSize(size = 100)
    @OneToMany(mappedBy = &quot;file&quot;, cascade = CascadeType.ALL, orphanRemoval = true)
    private List&lt;FileDetail&gt; fileDetailList = new ArrayList&lt;&gt;();

    public File() {

    }

}</code></pre>
<h3 id="결과-2">결과</h3>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/8d2362ed-f33d-4223-8e33-4b9800084d67/image.png" /></p>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/5bf46778-c205-433d-9868-4806fc1519a3/image.png" /></p>
<p>이처럼 수십 번 발생할 쿼리를 몇 번의 쿼리로 데이터를 가져오게 됩니다.</p>
<p>실제로  <strong>76번의 쿼리가 4개의 쿼리로 줄어들었습니다.</strong></p>
<p>또한 실행 시간도 약간이지만 단축되는 효과가 있었습니다.</p>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/ca5a60c6-b1c1-4a54-95b9-c383426e6c21/image.png" /></p>
<p>이것은 batchsize를 적용하기 전의 실행 시간이다. batchsize를 적용 후 3% 정도 단축되었습니다.</p>
<p>추가 조회 실행 후에도</p>
<ul>
<li>batchsize 적용 전 (2차)</li>
</ul>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/aa850639-fc3a-40e4-8b3d-d0745cebc1f7/image.png" /></p>
<ul>
<li>batchsize 적용 후 (2차)</li>
</ul>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/012a5154-1106-4790-91e4-c886656eb00d/image.png" /></p>
<p>약 10% 정도 단축되는 것을 볼 수 있습니다. </p>
<p><strong>이를 통해 batchsize를 알맞은 상황에 적용하면 쿼리도 최적화를 하고 성능도 개선할 수 있다는 것을 알 수 있습니다.</strong></p>
<h3 id="해결-방법-2fetchtype-설정">해결 방법 2(fetchType 설정)</h3>
<p>가게를 조회할 때 항상 사용되는 필드는 조인해서 하나의 쿼리에서 데이터를 가져오도록 설정합니다.</p>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/3cebc9da-8d09-430d-a01a-d1de1f559a7a/image.png" /></p>
<p><img alt="" src="https://velog.velcdn.com/images/take_the_king/post/73430c4b-92b4-467c-9b8f-75d264f4522e/image.png" /></p>
<h3 id="결과-3">결과</h3>
<p>왼쪽은 fetchType 이 Lazy 일 때 쿼리가 3번 발생하는 상황이고, fetchType 을 Eager로 설정해서 1번의 쿼리만 발생하는 상황입니다. 항상 같이 조회되는 데이터의 경우는 조인을 통해 같이 가져오는 방법이 성능 개선이 도움을 줄 수 있습니다.</p>
<hr />
<h2 id="4-결론">4. 결론</h2>
<ul>
<li><strong>인덱스 최적화, 데이터 캐싱, N+1 문제 해결</strong>을 통해 성능 개선을 이룰 수 있었습니다.</li>
<li>특히 <strong>인덱스 최적화와 Redis 캐싱</strong>이 성능 향상에 중요한 역할을 했습니다.</li>
<li>이러한 최적화 방법들은 각 상황에 맞게 사용하면, 시스템 성능을 크게 개선할 수 있습니다.</li>
</ul>
<table>
<thead>
<tr>
<th>개선 방법</th>
<th>성능 향상 비율</th>
<th>결과</th>
</tr>
</thead>
<tbody><tr>
<td>인덱스 최적화</td>
<td>10% ~ 80% 개선</td>
<td>작은 데이터에서 큰 성능 향상</td>
</tr>
<tr>
<td>Redis 캐싱</td>
<td>95% 개선</td>
<td>반복적인 조회에 매우 효과적</td>
</tr>
<tr>
<td>N+1 문제 해결</td>
<td>3% ~ 10% 개선</td>
<td>불필요한 쿼리 수를 줄여 성능 개선</td>
</tr>
<tr>
<td>FetchType 조정</td>
<td>20% 개선</td>
<td>하나의 쿼리로 데이터 조회</td>
</tr>
</tbody></table>
<h2 id="5-추후-고려-사항">5. 추후 고려 사항</h2>
<h3 id="51--elasticsearch-도입-고려">5.1  Elasticsearch 도입 고려</h3>
<p>검색 성능을 더욱 향상하기 위해 <strong>Elasticsearch</strong> 도입을 고려.</p>
<ul>
<li>빠른 텍스트 검색 가능</li>
<li>복합적인 필터링 및 랭킹 기능 제공</li>
</ul>
<h3 id="52-인덱스-추가">5.2 인덱스 추가</h3>
<p>검색 성능을 위해 더 다양한 인덱스 추가 고려</p>
<ul>
<li>알러지에 대한 인덱스 추가</li>
<li>복합 인덱스 추가</li>
</ul>